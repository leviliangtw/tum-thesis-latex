% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Implementation}\label{chapter:implementation}

\section{Deployment of the Prometheus Operator}

This section aims to detail the preparations and procedures for the setup of the Prometheus Operator. As mentioned in previous sections, the Prometheus Operator takes responsibility for deploying and managing Prometheus Agents and probe configurations, enhancing users' experience in active monitoring. The following subsections outline and explain the modifications and deployment of the Prometheus Operator. 

\subsection{Context}

Red Hat, Inc. has been actively promoting the integration of the Prometheus Operator into OpenShift. However, the most recent distribution hasn't incorporated the Prometheus Agent. Consequently, to avoid affecting the native deployment of the Prometheus Operator in OpenShift, a modified version of the operator, along with the associated \ac{CRD}s, is required at this stage. This adaptation ensures compatibility with current OpenShift configurations and employs the Prometheus Agent's advanced monitoring features. 

\subsection{Rebuild the Prometheus Operator and \ac{CRD}s}

To deploy a distinct Prometheus Operator for specific use cases and to prevent conflicts in environments where the native Prometheus Operator is already in use, it's essential to modify the group name of the targeted \ac{CRD}s. This process consists of implementing necessary adjustments and constructing a custom version. The steps involved are as follows: 

\begin{enumerate}
    \item \textbf{Edit the Group Name in the \ac{CRD} Manifests:} Modify the "apiVersion" field in each \ac{CRD} manifest by changing the group name part. This unique group name helps to distinguish the custom Prometheus Operator from the default installation. 
    \item \textbf{Update the Operator Code:} Besides the \ac{CRD} manifests, updating references to the group name in the Prometheus Operator's codebase is necessary. This ensures that the operator correctly interacts with the modified \ac{CRD}s. 
    \item \textbf{Build the Prometheus Operator Image with the Modified Group Name:} Once the changes are complete, build a new Docker image of the Prometheus Operator. 
    \item \textbf{Push the New Image to a Private Container Registry:} After building the new image, push it to your private container registry that the cloud platform can access. 
\end{enumerate}

These steps ensure that the modified Prometheus Operator functions independently of the native Openshift Prometheus Operator, thus allowing for customized configurations and deployments. 

\subsection{Deploy the Rebuilt Prometheus Operator}

Deploying a modified Prometheus Operator requires careful steps to ensure that it integrates seamlessly and functions correctly. This process not only involves applying the modified \ac{CRD}s but also deploying the Operator itself. The steps are as follows: 

\begin{enumerate}
    \item \textbf{Check the Targeted OpenShift Cluster:} Examine the targeted cluster to ensure it is ready for deployment. This includes checking for sufficient resources, access rights, etc. 
    \item \textbf{Apply the Modified CRDs:} Deploy modified CRDs to the cluster. 
    \item \textbf{Deploy the Prometheus Operator:} Use an OpenShift template or a Helm chart to deploy the Prometheus Operator. Ensure that the location of the rebuilt image is specified in the private container registry in the deployment configuration. 
    \item \textbf{Verify the Deployment:} Check the status of the Prometheus Operator to confirm the successful deployment by console or \ac{CLI} tools. It is essential to ensure that the Operator runs without errors and can manage Prometheus instances as expected. 
\end{enumerate}

These steps help identify potential issues with the modified Prometheus Operator and ensure its compatibility and functionality within the OpenShift ecosystem. By following these detailed steps, the deployment of the modified Prometheus Operator can be conducted smoothly. 

\section{Deployment of the Blackbox Exporter}

As an extension for the Prometheus ecosystem, the Blackbox Exporter has to be deployed additionally as the terminal to raise probes. This section will introduce the setup and steps for the Blackbox Exporter. 

\subsection{Build the Blackbox Exporter Image with Necessary Modules}

In Amadeus, two fundamental checks - the existence check and the certificate check - require the creation of specific modules for the Blackbox Exporter: 

\begin{itemize}
    \item \textit{Existence Check Module:} Confirms network connectivity through a \ac{HTTP} GET request to an endpoint, ensuring a successful response. Configurable parameters include the \ac{URL}, anticipated \ac{HTTP} status codes, and timeout settings. 
    \item \textit{Certificate Check Module:} Validate the existence and \ac{TLS} certificates of \ac{HTTPS} endpoints to ensure the presence, validity, and signing. Configuration includes the \ac{URL}, expiry thresholds, and CA verification details. 
\end{itemize}

These modules are used to build a customized Blackbox Exporter image, which is subsequently deployed in the environment. The construction process involves the following steps: 

\begin{enumerate}
    \item \textbf{Create the Configuration of Two Modules:}
    Create a YAML configuration file for the Blackbox Exporter that includes these two modules. For example:
    \begin{verbatim}
    modules:
      existence_check:
        prober: http
        timeout: 30s
        http:
          preferred_ip_protocol: "ip4"
      certificate_check: 
        prober: http
        timeout: 30s
        http:
          fail_if_not_ssl: true
          tls_config:
            ca_file: "/certs/ca.crt"
          preferred_ip_protocol: "ip4"
    \end{verbatim}
    \item \textbf{Build the Blackbox Exporter Image:}
    Once the configuration file is ready, incorporate it into the Blackbox Exporter Docker image for a new build. This involves creating a Dockerfile that uses the Blackbox Exporter base image, adds the configuration file, and sets necessary environment variables. Here is the Dockerfile example: 
    \begin{verbatim}
    FROM prom/blackbox-exporter:v0.24.0
    COPY blackbox-config.yml /etc/blackbox_exporter/config.yml
    ADD certs /certs
    EXPOSE 9115
    ENTRYPOINT [ "/bin/blackbox_exporter" ]
    CMD [ "--config.file=/etc/blackbox_exporter/config.yml" ]
    \end{verbatim}
    \item \textbf{Push the Image to the Private Container Registry:}
    After building the image, push it to a private container registry for deployment. Ensure that the cluster is authorized to pull images from this private registry. 
\end{enumerate}

Following these steps, a customized Blackbox Exporter with specific modules for existence and certificate checks is created, aiming at the needs of Amadeus's infrastructure monitoring. This ensures targeted and efficient monitoring, specifically designed for the network and certificate validation requirements. 

\subsection{Deploy the Blackbox Exporter}

Deploying the customized Blackbox Exporter is straightforward, with the image already prepared with the necessary configurations. To ensure a successful deployment with the monitoring platform, follow these steps: 

\begin{enumerate}
    \item \textbf{Deploy the Blackbox Exporter:}
    Depending on the preference and the existing setup, the deployment can be done using either an OpenShift template or a Helm chart. 
    \item \textbf{Verify the Deployment:}
    After the deployment, ensure it functions correctly by checking its status via console or \ac{CLI}. Necessary checks include the pod's running status, resource utilization, log outputs for errors, and connectivity to targets. This step is essential to verify the operational readiness for monitoring. 
\end{enumerate}

By following these steps, the deployment of the Blackbox Exporter can be ensured to provide reliable monitoring capabilities for the cluster.

\subsection{Load Balancing via the Service}

In the context of container orchestration, leveraging an OpenShift Service for load distribution at OSI Layer 4 is preferable and more efficient when there is no requirement for Layer 7 capabilities, such as path-based routing, thereby minimizing load-related overhead. The Service functions as a layer above the pods, creating a consolidated access point that distributes traffic evenly among different Blackbox Exporter pod instances. This method leverages kube-proxy's iptables mode for efficient traffic distribution. The following steps guide setting up load balancing with the Service: 

\begin{enumerate}
    \item \textbf{Create the Service Resource for the Blackbox Exporter:}
    Define a Service resource for the Blackbox Exporter. This Service will route traffic to the selected pods. 
    \item \textbf{Check the Connectivity of the Service Resource:}
    Once the Service is created, it gets assigned a ClusterIP and a DNS record within the cluster. Check the connectivity to this DNS record to ensure that the Service is accessible. You can do this by running a DNS lookup or a simple curl command from a pod within the same cluster: 
    \begin{verbatim}
    $ nslookup blackbox-exporter-service
    $ curl http://blackbox-exporter-service/
    \end{verbatim}
\end{enumerate}

The created Service of the Blackbox Exporter serves as a central gateway for Prometheus Agent requests. The iptables proxy mode of the kube-proxy naturally directs traffic to available pods in a random and balanced way. This configuration ensures efficient and direct routing for monitoring traffic. 

\subsection{Scalability via the Horizontal Pod Autoscaler (\ac{HPA})}

The \ac{HPA} boosts elasticity and cost efficiency by enabling dynamic adjustment of pod replicas in response to varying workloads, thus enhancing application scalability. It scales the number of pod replicas based on metrics like CPU usage. This section explains how to implement an \ac{HPA} for the Blackbox Exporter, allowing it to scale dynamically according to workload changes: 

\begin{enumerate}
    \item \textbf{Ensure the Metrics Server:}
    The \ac{HPA} requires metric data to make scaling decisions. Ensure that the Metrics Server responsible for collecting resource usage data is deployed in the cluster. 
    \item \textbf{Create the \ac{HPA} Resource:}
    Define an \ac{HPA} resource in YAML format. Specify the deployment to scale, the metrics to be used for decisions, and the desired target values for those metrics. 
    \item \textbf{Apply the \ac{HPA} Configuration:}
    Apply the \ac{HPA} configuration to your Kubernetes cluster. 
    \item \textbf{Adjust \ac{HPA} Parameters:}
    Based on the observed performance, you might need to adjust the \ac{HPA} parameters, such as the target \ac{CPU} utilization or the maximum number of replicas. Update the \ac{HPA} configuration file and reapply it as necessary.
\end{enumerate}

Implementing an \ac{HPA} for the Blackbox Exporter ensures that the deployment can adapt to changing demands automatically, maintaining optimal performance and resource utilization.

\section{Deployment of the Prometheus Agent}

To utilize the Prometheus Agent, in addition to deploying the instance, it's critical to set up the scraping metrics from targets depending on the configuration file. With the management by the Prometheus Operator, the efforts of deploying, loading, and reloading the instance could be released, greatly easing the maintenance complexity. In this section, utilizing the Prometheus Operator to deploy and maintain the Prometheus Agent will be discussed in detail. 

\subsection{Configure the Prometheus Agent Configuration based on the PrometheusAgent \ac{CRD}}

The Prometheus Operator monitors the PrometheusAgent \ac{CRD}, which is derived from the Prometheus configuration. The primary settings in this project are the "probeSelector" and "remoteWrite" fields, which are responsible for probe configurations and specifying the remote write endpoint, respectively. 

The probeSelector functions as the Label Selector in this \ac{CRD}, enabling users to define the labels of probes that will be selected by the Prometheus Agent. This feature allows the Prometheus Agent to distinguish the Probe used by the active monitoring platform from other monitoring systems, even though they might utilize the same official \ac{CRD}. 

The remoteWrite feature enables users to configure the remote endpoint to which the Prometheus Agent uploads metrics. By establishing the distributed Thanos Receive as the remote write endpoint in each local cluster, this architecture spreads some computational tasks to the edge, enhancing efficiency and availability. 

\subsection{Deploy the Prometheus Agent Configuration based on the PrometheusAgent \ac{CRD}}

Deploying a custom object from the PrometheusAgent \ac{CRD}, which is monitored by the Prometheus Operator involves several steps to ensure successful integration and configuration. This process can be broken down into the following stages:

\begin{enumerate}
\item \textbf{Define a Custom Object from the PrometheusAgent \ac{CRD}:}
Create a custom object in YAML format with the necessary specifications of the PrometheusAgent \ac{CRD}, including "probeSelector" and "remoteWrite" configurations. Here is an example:
\lstset{upquote=true}
\begin{lstlisting}
    apiVersion: monitoring.coreos.com/v1
    kind: PrometheusAgent
    metadata:
      name: example-prometheus-agent
      namespace: monitoring
    spec:
      probeSelector:
        matchLabels:
        apps: active-monitoring
      remoteWrite:
        - url: http://thanos-receive.monitoring.svc.cluster.local:19291/api/v1/receive
\end{lstlisting}
\item \textbf{Apply a Custom Object:}
Deploy the Prometheus Agent by applying the custom object in the cluster. 
\item \textbf{Verify the Deployment:}
Once the custom object is deployed, verify its status and ensure that the Prometheus Operator deploys the Prometheus Agent. 
\end{enumerate}

Following these steps, the Prometheus Agent is successfully deployed and configured in the cluster, leveraging the Prometheus Operator for efficient management. 

\section{Create the Monitoring Configuration}

As of now, the preliminary settings have been completed, and users can utilize the Probe \ac{CRD} to create an active monitoring configuration. This section will provide detailed instructions on configuring it, followed by the necessary steps. 

\subsection{Configure the Monitoring Configuration Based on the Probe \ac{CRD}}

With the Probe \ac{CRD}, users can conveniently define monitoring for a set of targets, facilitating cloud-native configuration management within the cloud platform. The module, prober, and targets are the three most important fields for the configuration. 

The "module" field in Prometheus configures how targets are probed, often using settings from the Blackbox exporter. The "prober" field specifies the prober details, with the essential "prober.url" parameter. "targets" defines a set of static or dynamic targets for the prober to monitor. Also, the "metadata.labels" needs to be set in coherent with the "probeSelector.matchLabels" in PrometheusAgent. 

\subsection{Deploy the Monitoring Configuration Based on the Probe \ac{CRD}}

Deploying the custom object from the Probe \ac{CRD} is the last crucial step in active monitoring using Prometheus. It involves creating and applying the monitor configuration, ensuring that the specified targets are actively monitored based on the defined parameters. Here are the steps for the deployment:

\begin{enumerate}
    \item \textbf{Define a Custom Object from the Probe \ac{CRD}:}
    Create a custom object in YAML format to establish the desired monitoring configurations. Ensure that this object includes all essential fields, such as module, prober, and targets. Additionally, confirm that the metadata.labels within the object match the probeSelector.matchLabels specified in the previous section. For example, please refer to the provided code below. 
        \lstset{upquote=true}
        \begin{lstlisting}
            apiVersion: monitoring.ruup.amadeus.net/v1
            kind: Probe
            metadata:
              labels:
                apps: active-monitoring
              name: probe-example
            spec:
              interval: 15s
              jobName: probe-example
              module: existence_check
              prober:
                path: /probe
                scheme: http
                url: blackbox-exporter-service:9115
              targets:
                staticConfig:
                  static:
                    - 'http://example.com/'
        \end{lstlisting}
    \item \textbf{Apply a Custom Object:}
    Once the custom object is ready, apply it to the targeted cluster. 
    \item \textbf{Verify the Deployment:}
    After applying the object, verify that it has been successfully deployed. 
    \item \textbf{Check the Monitoring Results:}
    Once the object is deployed, the Prometheus Agent will begin monitoring the specified targets according to the intervals and parameters set in the configuration. The monitoring data and metrics can be viewed on the dashboards of the Prometheus Agent or the Blackbox Exporter. 
\end{enumerate}

After these steps, the custom object based on the Probe \ac{CRD} is deployed, enabling active monitoring of specified targets using Prometheus Agent. This setup facilitates efficient and dynamic monitoring in cloud-native platforms. 

\section{GitOps for managing \ac{CRD}s}

GitOps can automate and manage infrastructure configurations using Git as a single source. In this section, we realize GitOps principles to manage \ac{CRD}s using, the Argo CD, a declarative continuous delivery tool for GitOps. 

\subsection{Create Git Repository for \ac{CRD}s}

\begin{enumerate}
    \item \textbf{Initialize a Git Repository:} Create a new Git repository, which will host all the \ac{CRD} manifests and related configurations. Users could use GitHub, GitLab, or any other Git hosting service for this purpose.
    \item \textbf{Add \ac{CRD} Manifests:} Upload \ac{CRD} manifests into the repository with a well-set structure and directory. Ensure each \ac{CRD} manifest is written in YAML format and correctly structured.
    \item \textbf{Version Control:} Adopt the branching strategy to maintain different versions or environments. Then, commit and push changes to the remote repository. 
\end{enumerate}

\subsection{Register the Repository in Argo CD}

\begin{enumerate}
    \item \textbf{Add the Repository with Argo CD UI:} In the Argo CD dashboard, navigate to the settings and add your Git repository. Provide the necessary credentials if your repository is private. 
    \item \textbf{Configure Repository Settings:} Configure the synchronization settings, such as automated sync policies, sync frequency, and other repository-specific settings as required by your deployment strategy. 
\end{enumerate}

\subsection{Deploy \ac{CRD}s with Argo CD}

\begin{enumerate}
    \item \textbf{Create an Application in Argo CD:} In Argo CD, "Application" represents a set of resources to be deployed. Create a new Application and link it to the directory in your Git repository where the \ac{CRD} manifests are stored. 
    \item \textbf{Define Sync Policy:} Choose an appropriate synchronization policy for your \ac{CRD}s. You can opt for manual sync, which requires manual intervention to apply changes, or automatic sync, where changes in the Git repository are automatically applied to the cluster. 
    \item \textbf{Version Management:} For any updates or changes in \ac{CRD}s, update the manifests in the Git repository. Argo CD will synchronize these changes based on the configured sync policy, ensuring that your cluster state matches the desired state defined in Git. 
\end{enumerate}

By integrating GitOps practices for \ac{CRD} management, organizations can achieve automated, reliable, and version-controlled deployment processes, aligning infrastructure and application states with complex configurations.